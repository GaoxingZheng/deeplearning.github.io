#### Paper Title : Neural Decoding of Visual Imagery During Sleep

#### Paper website : https://science.sciencemag.org/content/340/6132/639

@ Gaoxing Zheng

#### 一、摘要

> 睡眠过程中得到视觉意象一直都是被持续关注的话题，但它的私密性阻碍了客观分析。这里，我们提出了一种神经解码方法，在词汇和图像数据库的帮助下发现人类功能性磁共振成像模式和口头报告之间的联系，在给定测量的大脑活动的情况下，运用机器学习模型预测睡眠开始期(sleep-onset)视觉图像的内容。从视觉皮质区刺激引起的大脑活动得到的解码模型显示正确的分类、检测和识别的内容。我们的研究结果表明，睡梦中特定视觉体验是由刺激感知共享的大脑活动模式表征，这为使用客观神经测量来揭示梦的主观内容提供了一种方法。

#### 二、正文

> 做梦是一种主观的睡眠体验，通常伴随着生动的视觉内容。先前的研究试图将生理状态与做梦联系起来，但没一个研究表明特定的视觉内容是如何在大脑中表现出来的。基于机器学习的分析技术的出现使得解码刺激和任务诱导的大脑活动模式成为可能，从而揭示视觉内容。我们将这种方法扩展到对睡眠中自发脑活动的解码。尽管做梦常常与快速眼动睡眠阶段(REM)有关，最近的研究表明，做梦与REM睡眠是分离的，可以在非REM期间经历。我们关注的是睡眠(催眠)开始时的视觉想象(幻觉)期(sleep stage 1 or 2)，因为它允许我们通过重复醒来和记录参与者视觉体验的口头报告来收集许多观察。在开始睡眠和REM期间，关于觉醒的报告具有相同的一般特征，如频率、时间和内容，但在几个方面的差异，包括感情成分。我们使用词汇数据库分析口头报告，为视觉表象的内容创造系统的标签。我们假设，睡眠中视觉表象的内容至少部分是由刺激表征所共有的视觉皮层活动模式所表征的。因此，我们从Web图像数据库中训练解码器对自然图像诱导的大脑活动进行解码。
>
> 三名被试参与了磁共振睡眠实验，其中当检测到脑电信号时，他们被叫醒，要求受试者自由地做一份口头报告，描述他们在醒来前的视觉体验。我们重复这一过程，以达到每位受试者至少具有200次视觉报告的唤醒次数。平均而言，我们每342.0秒唤醒参与者一次，75%以上的唤醒中报告了视觉内容。离线睡眠阶段评分(图S2)进一步选择唤醒，以排除紧接在唤醒前的阶段的污染（对于被试1到3，分别有235，198个186次唤醒用于解码分析）。
>
> 从收集的报告中，描述视觉对象或场景的单词被手工提取并映射到WordNet，WordNet是一个词汇数据库，在这个词汇数据库中，语义相似的单词按照层次结构分组为"synset"。使用语义层次结构，我们将提取的可视单词分组到每个参与者至少10个报告中出现的基本同义词集中(对于参与者1到3，分别收集到26，18和16个同步集)。每次唤醒前获得的fMRI数据都用一个视觉内容向量进行标记，其中的每个元素都表示在随后的报告中存在或不存在基本同义词集(图2B和图S3)。我们还从ImageNet收集了每个基本同义词的图像，这是一个图像数据库，其中Web图像根据WordNet分组，或者来自谷歌图像，用于解码训练。
>
> 我们通过训练线性支持向量机(SVMs)在每个人观看每个基本同义词集的Web图像时对所测得的fMRI数据进行训练，构造解码器。在更高的视觉皮层[HVC；腹侧区域覆盖枕外侧复合体(LOC)，梭状脸区(FFA)和旁海马位置区(PPA)：1000个voxels]，更低的视觉皮层(LVC；V1到V3结合；1000个voxels)或者子区域(每个区域400个voxels)的多体素模式被用作解码器的输入。
>
> 首先，用fMRI对两个基本同义词(三个volume的平均数据对应于9s的刺激块)的刺激图像的响应训练二分类器，并在睡眠样本上(在唤醒之前立即获得平均三个volume(9s)的数据)进行测试，其仅包含两个同义词集中的一个，同时忽略其他并发同义词集(图3A)。我们只使用了同义词集对，其中一个同义词出现至少在10次口头报告中，而不与另一个同时出现(对参与者1~3分别有201，118和86次配对)。高级视觉区域的成对解码准确率的分布与来自在相同刺激诱发的fMRI数据上训练的解码器的分布一起显示，具有随机打乱的同义词标签(图3B；图S4)。平均解码准确率为60%，95%的置信区间[(59%,61%)；三名被试混在一起]，显著地(基于Wilcoxon符号秩和检验和置换检验)高于标签打乱的解码器。
>
> 为了研究感知和睡眠启动(sleep-onset)意象之间的共性，我们着重研究了在每个刺激和睡眠实验中产生特定内容模式的同义词集对(在每个刺激和睡眠数据集中具有高交叉验证分类准确率的同义词对；图S5和S6)。有了这些选定的同义词对，甚至能获得更高的准确率(平均70.3%，置信区间CI(68.5,72.1)；图3B，深蓝色；图S4，每个个体的情况；表S5到S7，选定的成对集列表)，表明内容特定模式在感知和睡眠启动的意象之间高度一致。同义词对的选择，使用了测试(睡眠)数据的知识，不会对标签打乱解码器的零分布产生偏差(图3B，黑色)，因为睡眠数据集中内容特异性并不意味着两个数据集之间的共性。
>
> 额外的分析揭示了多体素，而不是平均活动水平，对解码更关键(图S7和图S8)。我们还发现，同义词集之间解码性能的变化至少可以部分地解释成对同义词集之间的语义差异。跨meta-类别(human, object, scene和其它；表S2到S4)成对的同义词集的解码精度显著地高于meta-类内的同义词(Wilcoxon符号秩和检验，P<0.001；图3C和图S9)。然而，及时在meta-类内，平均解码准确率仍显著性地高于机会水平(chance level)，表示对精细对象类别的特异性。
>
> 不同视觉区域的平均解码精度如图3D所示(图S10，个体情况)，所有配对下的LVC(低级视觉皮层)得分为54.3%，选定配对下(三名被试混合在一起)的得分为57.2%，置信区间(CI)为(54.2%，60.2%)。性能显著地在机会水平之上，但是差于高级视觉皮层。个体区域(V1到V3，LOC，FFA和PPA)展示了在视觉处理通路上缓慢提高的准确率，将逐渐复杂的响应属性从低级图像特异性映射到对象级特征中去。当时间窗口移动时，解码准确率峰值出现在大约唤醒前的0到10s左右(图3E和图S11；没有对血氧动力学的延迟进行校正)。唤醒前的高准确率可能由于血氧动力学延迟和大的时间窗。因此，口头报告很可能反映了醒来之前大脑的活动。
>
> 为了在给定任意睡眠数据的情况下读出更丰富的内容，我们接下来执行了一个多标签解码分析，其中每个同义词集存在或不存在是由一对解码器组合而成的同义词集检测器预测(图4A)。同义词(synset)检测器提供了一个连续的分数，指示每个报告中出现synset的可能性有多大。通过改变输出分数的检测阈值，我们计算了基本同步集的ROC曲线(图4B，参与者2中的HVC，唤醒前立即时移；图S12，所有参与者情况)，使用曲线下的面积(AUC)量化检测性能。尽管不同的synsets性能有所不同，但总共60个synsets中检测到18个synsets高于机会水平(Wilcoxon符号秩和检验，未校正的P<0.05)，大大超过偶然期望的同义词集的数量(0.05*60=3)。
>
> 使用AUC，我们比较了不同视觉区内分组到meta-类别的单个同义词集的解码性能。总的来说，HVC的性能要优于LVC，这与成对解码的性能是一致的[图2]，与成对解码的性能一致[图S13；三名被试混合在一起；方差分析(ANOVA),P=0.003]。尽管V1到V3在meta-类别中没有表现出不同的性能，但是较高的视觉区域对meta-类别有明显的依赖关系(图4C和图S13)。特别是，FFA显示了与human同义词集更好的性能，而PPA显示了与scene同义词集更好的性能[ANOVA(交互效应)，P=0.001]，与这些区域已知的响应特性一致。LOC和FFA显示了类似的结果，可能是因为我们的功能定位器选择了部分重叠的体素。
>
> 在每个睡眠样本中，各个同义词集的输出得分显示出多样性和动态特性(图4D，图S14，影片S1和S2)。这些profiles可能反映视觉内容的动态变化，包括那些甚至在接近觉醒之前就经历过的变化。平均而言，有一个普遍的趋势，报告的同义词的得分通常在醒来时增加(图4E和图S15)。如果报告中未出现的同义词与报告的同义词具有较高的共现关系，则会显示更高的分数(图4E；给定报告的同义词组的前15%条件概率的同义词，根据每个参与者的全内容向量计算得出)。共生的影响与语义相似度的影响是相互独立的(图3C)，因为这两个因素(高/低共现和内/跨meta-类别)对未报告的同义词的分数对具有中度相互作用的未报告的同义词的得分具有非常显著的影响(P = 0.016)。报告的同义词得分显著地高于甚至在相同meta-类内的未报告的同义词集(Wilcoxon符号秩和检验，P<0.001)。口头报告不太可能描述睡眠中视觉体验的全部细节，并且即使没有报告所有内容，也可能一起经历具有高度一般共现的内容(例如街道和汽车)。因此未报告的同义词的高分可能表示未报告但实际在睡眠中出现的视觉内容。
>
> 最后，为了探索潜在的多标签解码在区分众多内容方面的潜力，我们进行了识别分析。输出得分(得分向量)用于通过选择与得分向量最相关(对每个睡眠样本重复100次来获得准确的识别率)的候选者来识别可变数目的候选者中的真实视觉内容向量(真实向量+具有每个同义词匹配概率的随机向量)。尽管这个准确率没有在先前使用刺激诱发的脑活动的准确率那么高，但所有集合大小的性能都超过了机会水平(图4F，HVC，三名被试混合在一起；图S16，个体参与者)。对扩展的视觉内容向量进行相同的分析，其中假设未报告的同义词集具有与已报告的同义词集高并发性。结果表明扩展后的视觉内容向量识别效果更好，表明多标签解码输出可以同时表征已报告的内容和未报告的内容。
>
> 总之，我们的研究结果提供了证据，证明睡眠期间视觉体验的特定内容由与刺激表征共享的视觉皮层活动模式表征，并可以从这些模式中读出。通过使用数据库辅助机器学习解码器发现复杂的大脑活动模式和非结构化的口头报告之间的联系，我们的方法扩展了先前关于睡眠中大脑(重新)激活以及做梦和大脑活动之间关系的研究。研究结果表明，感知等价原理假设了感知和意象的共同神经基础，并将其推广到睡眠过程中自发产生的视觉体验。虽然我们已经用HVC演示了语义解码，但这并不排除用LVC解码底层特性的可能性。这里给出的解码本质上是回顾性的：根据收集到的报告，在睡眠实验后重构解码器。然而，由于所报道的同义词集在实验前半部分和后半部分之间有很大的重叠(60个基本同义词集中有59个出现在这两部分)，相同的解码器可能适用于未来的睡眠数据。快速眼动(REM)和睡眠开始报告之间的相似性以及快速眼动睡眠期间的视觉皮层激活表明，同样的解码器也可以用来解码快速眼动图像。我们的方法可能会进一步超越睡眠阶段和可报告经验的界限，揭示与刺激表征相关的自发大脑活动的动力学。我们希望它能够更好地理解梦境和自发神经事件的功能。
